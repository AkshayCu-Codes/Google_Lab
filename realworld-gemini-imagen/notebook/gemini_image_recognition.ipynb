{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c6d378",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ”¬ AI Image Recognition with Gemini on Vertex AI\n",
    "\n",
    "## ðŸ§  Objective\n",
    "In this lab, you will build an AI image recognition application using the **Gemini** model on **Vertex AI** (Google Cloud). Youâ€™ll learn to:\n",
    "- Connect to Vertex AI using the Vertex AI SDK\n",
    "- Load a pre-trained generative AI model (Gemini)\n",
    "- Send image + text prompts to the AI\n",
    "- Extract and interpret text-based answers from the AI\n",
    "- Understand the integration of GenAI in real-world applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ed29a",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cffaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google import genai\n",
    "from google.genai.types import HttpOptions, Part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a00a8",
   "metadata": {},
   "source": [
    "## ðŸ”Œ Step 2: Connect to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afa40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695168eb",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 3: Generate Content using Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1528b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=[\n",
    "        \"What is shown in this image?\",\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://cloud-samples-data/generative-ai/image/scones.jpg\",\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e748095",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Step 4: Set Environment Variables\n",
    "\n",
    "Use this in a terminal before running the script:\n",
    "\n",
    "```\n",
    "export GOOGLE_CLOUD_PROJECT='qwiklabs-gcp-02-1818266e39c6'\n",
    "export GOOGLE_CLOUD_LOCATION='europe-west1'\n",
    "export GOOGLE_GENAI_USE_VERTEXAI=True\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11838d5c",
   "metadata": {},
   "source": [
    "\n",
    "## â–¶ï¸ Step 5: Execute the Script (if running as a Python file)\n",
    "\n",
    "```\n",
    "/usr/bin/python3 /genai.py\n",
    "```\n",
    "\n",
    "> Replace `/genai.py` with your script path if different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170c0b2",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ’¡ Explanation\n",
    "\n",
    "- The model used is `gemini-2.0-flash-001`, a lightweight version of the Gemini family optimized for fast inference.\n",
    "- `Part.from_uri` sends the image from a public Google Cloud bucket.\n",
    "- The prompt `\"What is shown in this image?\"` asks Gemini to describe the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde4f0a",
   "metadata": {},
   "source": [
    "## ðŸ§ª Try It Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9de789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=[\n",
    "        \"Describe this scene in detail.\",\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://cloud-samples-data/generative-ai/image/paris.jpg\",\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090805dc",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Conclusion\n",
    "\n",
    "In this lab, you learned how to:\n",
    "- Connect to Vertex AI using Python SDK\n",
    "- Use Gemini to analyze images\n",
    "- Craft multimodal prompts (image + text)\n",
    "- Understand basic AI integration workflows in real applications\n",
    "\n",
    "Continue exploring by adjusting the prompt or using your own images in GCS!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5519f",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“š References\n",
    "- [Vertex AI Documentation](https://cloud.google.com/vertex-ai)\n",
    "- [Gemini API Overview](https://ai.google.dev/)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}